name: Visual Comparison Test

on:
  workflow_dispatch:
    inputs:
      brand:
        description: 'Brand code (optional)'
        required: false
      pageType:
        description: 'Page type (optional)'
        required: false
      baseline:
        description: 'Baseline URL to compare'
        required: true
      modified:
        description: 'Modified URL to compare'
        required: true
  pull_request:
    types: [opened, synchronize, reopened]

permissions:
  contents: read
  pull-requests: write

jobs:
  extract-urls:
    runs-on: ubuntu-latest
    outputs:
      url_pairs: ${{ steps.combine.outputs.url_pairs }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Extract URLs from PR Description
        id: extract
        if: github.event_name == 'pull_request'
        run: |
          echo "Processing PR description for visual test configurations..."
          
          # Get PR description and remove carriage returns
          DESCRIPTION=$(echo "${{ github.event.pull_request.body }}" | tr -d '\r')
          
          # Create a temporary file with the description for easier processing
          echo "$DESCRIPTION" > pr_description.txt
          
          # Debug info
          echo "===== PR DESCRIPTION ====="
          cat pr_description.txt
          echo "=========================="
          
          # Extract URL pairs using a more robust approach
          cat > extract_urls.awk << 'EOL'
          BEGIN { 
            FS=": "; 
            OFS=""; 
            json="["; 
            first=1;
            brand="";
            pageType="";
            baseline="";
            modified="";
            in_visual_section=0;
          }
          
          /^## Visual Test/ { 
            in_visual_section=1;
            # Reset values for new section
            brand="";
            pageType="";
            baseline="";
            modified="";
          }
          
          /^##/ && !/^## Visual Test/ { 
            in_visual_section=0; 
          }
          
          in_visual_section && /^- Brand:/ { 
            brand=$2; 
            gsub(/^[ \t]+|[ \t]+$/, "", brand);
            # Escape special characters for JSON
            gsub(/&/, "\\\\&", brand);
            gsub(/"/, "\\\\\"", brand);
            print "Found Brand: " brand > "/dev/stderr";
          }
          
          in_visual_section && /^- PageType:/ { 
            pageType=$2; 
            gsub(/^[ \t]+|[ \t]+$/, "", pageType);
            # Escape special characters for JSON
            gsub(/&/, "\\\\&", pageType);
            gsub(/"/, "\\\\\"", pageType);
            print "Found PageType: " pageType > "/dev/stderr";
          }
          
          in_visual_section && /^- Baseline:/ { 
            baseline=$2; 
            gsub(/^[ \t]+|[ \t]+$/, "", baseline);
            print "Found Baseline: " baseline > "/dev/stderr";
          }
          
          in_visual_section && /^- Modified:/ { 
            modified=$2; 
            gsub(/^[ \t]+|[ \t]+$/, "", modified);
            print "Found Modified: " modified > "/dev/stderr";
            
            # If we have all required fields, add to JSON
            if (brand != "" && baseline != "" && modified != "") {
              if (pageType == "") pageType = "page";
              
              if (!first) json=json",";
              json=json" { \"brand\": \""brand"\", \"pageType\": \""pageType"\", \"baseline\": \""baseline"\", \"modified\": \""modified"\" }";
              print "Added pair to JSON" > "/dev/stderr";
              first=0;
              
              # Reset for next set within the same section
              brand="";
              pageType="";
              baseline="";
              modified="";
            }
          }
          
          END { 
            json=json" ]"; 
            print json;
          }
          EOL
          
          URL_PAIRS=$(awk -f extract_urls.awk pr_description.txt)
          
          # Ensure valid JSON output
          if [[ -z "$URL_PAIRS" || "$URL_PAIRS" == "[ ]" ]]; then
            echo "No URL pairs found in PR description. Please format your PR description with sections like:"
            echo "## Visual Test"
            echo "- Brand: BrandName"
            echo "- PageType: HomePage"
            echo "- Baseline: https://baseline-url.com"
            echo "- Modified: https://modified-url.com"
            URL_PAIRS="[]"
          else
            echo "Found URL pairs in PR description: $URL_PAIRS"
          fi
          
          # Validate JSON
          echo "Validating JSON format..."
          if ! echo "$URL_PAIRS" | jq empty; then
            echo "Error: Invalid JSON format"
            echo "Raw JSON: $URL_PAIRS"
            # Provide a fallback default value
            URL_PAIRS='[{"brand":"default","pageType":"page","baseline":"https://example.com","modified":"https://example.com"}]'
            echo "Using fallback URL pairs: $URL_PAIRS"
          fi
          
          echo "url_pairs=$URL_PAIRS" >> $GITHUB_OUTPUT

      - name: Set Manual URL Pair
        id: manual
        if: github.event_name == 'workflow_dispatch'
        run: |
          BRAND="${{ github.event.inputs.brand }}"
          PAGE_TYPE="${{ github.event.inputs.pageType }}"
          BASELINE="${{ github.event.inputs.baseline }}"
          MODIFIED="${{ github.event.inputs.modified }}"
          
          # Default values if not provided
          BRAND="${BRAND:-manual}"
          PAGE_TYPE="${PAGE_TYPE:-page}"
          
          # Escape special characters for JSON
          BRAND_ESCAPED=$(echo "$BRAND" | sed 's/&/\\&/g; s/"/\\"/g')
          PAGE_TYPE_ESCAPED=$(echo "$PAGE_TYPE" | sed 's/&/\\&/g; s/"/\\"/g')
          
          # Create JSON array with the manually provided URLs
          URL_PAIR="[{ \"brand\": \"${BRAND_ESCAPED}\", \"pageType\": \"${PAGE_TYPE_ESCAPED}\", \"baseline\": \"$BASELINE\", \"modified\": \"$MODIFIED\" }]"
          
          echo "Manual input values:"
          echo "Brand: $BRAND"
          echo "Page Type: $PAGE_TYPE"
          echo "Baseline: $BASELINE"
          echo "Modified: $MODIFIED"
          
          # Validate JSON
          echo "Validating JSON format..."
          if ! echo "$URL_PAIR" | jq empty; then
            echo "Error: Invalid JSON format"
            echo "Raw JSON: $URL_PAIR"
            # Provide a fallback default value
            URL_PAIR='[{"brand":"manual","pageType":"page","baseline":"'"$BASELINE"'","modified":"'"$MODIFIED"'"}]'
            echo "Using fallback URL pairs: $URL_PAIR"
          fi
          
          echo "url_pairs=$URL_PAIR" >> $GITHUB_OUTPUT
          echo "Manual URL pair: $URL_PAIR"

      - name: Combine URL Pairs
        id: combine
        run: |
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            URL_PAIRS="${{ steps.extract.outputs.url_pairs }}"
          else
            URL_PAIRS="${{ steps.manual.outputs.url_pairs }}"
          fi
          
          echo "Combined URL pairs: $URL_PAIRS"
          
          # Final validation check
          if [ -z "$URL_PAIRS" ] || [ "$URL_PAIRS" == "[]" ]; then
            echo "Warning: Empty URL pairs. Using default values."
            URL_PAIRS='[{"brand":"default","pageType":"page","baseline":"https://example.com","modified":"https://example.com"}]'
          fi
          
          echo "url_pairs=$URL_PAIRS" >> $GITHUB_OUTPUT

      - name: Validate URL Pairs
        if: github.event_name == 'pull_request'
        run: |
          URL_PAIRS='${{ steps.combine.outputs.url_pairs }}'
          
          echo "Final URL pairs to be used: $URL_PAIRS"
          
          if [ "$URL_PAIRS" == "[]" ]; then
            echo "::warning::No valid URL pairs found in PR description. Please format your PR description with sections like:"
            echo "::warning::## Visual Test"
            echo "::warning::- Brand: BrandName"
            echo "::warning::- PageType: HomePage"
            echo "::warning::- Baseline: https://baseline-url.com"
            echo "::warning::- Modified: https://modified-url.com"
          else
            echo "Valid URL pairs found. Visual tests will run."
          fi

  debug-matrix:
    needs: extract-urls
    runs-on: ubuntu-latest
    steps:
      - name: Debug matrix input
        run: |
          echo "Debug URL pairs from previous job:"
          echo '${{ needs.extract-urls.outputs.url_pairs }}'
          
          # Check if the JSON is valid
          if echo '${{ needs.extract-urls.outputs.url_pairs }}' | jq empty; then
            echo "JSON is valid"
          else
            echo "JSON is invalid"
          fi
          
          # Try to parse with fromJson
          JSON_PARSED='${{ toJSON(fromJson(needs.extract-urls.outputs.url_pairs)) }}'
          echo "Parsed JSON: $JSON_PARSED"

  visual-test:
    needs: [extract-urls, debug-matrix]
    runs-on: ubuntu-latest
    timeout-minutes: 30  # Added timeout to ensure tests have enough time to complete
    if: ${{ needs.extract-urls.outputs.url_pairs != '[]' }}
    strategy:
      fail-fast: false
      max-parallel: 2  # Limit parallel jobs to avoid rate limiting
      matrix:
        pair: ${{ fromJson(needs.extract-urls.outputs.url_pairs) }}
        viewport: [desktop, tablet, mobile]
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: 'npm'

      - name: Install Dependencies
        run: |
          npm ci || npm install
          npm install -g cypress

      - name: Print Test Information
        run: |
          echo "Running visual test for:"
          echo "Brand: ${{ matrix.pair.brand }}"
          echo "Page Type: ${{ matrix.pair.pageType }}"
          echo "Viewport: ${{ matrix.viewport }}"
          echo "Baseline URL: ${{ matrix.pair.baseline }}"
          echo "Modified URL: ${{ matrix.pair.modified }}"

      - name: Run Cypress Tests
        id: cypress
        continue-on-error: true
        run: |
          echo "Running ${{ matrix.viewport }} regression test..."
          
          # Create cypress.env.json file with the required environment variables
          # Unescape any escaped characters in the brand and page type
          BRAND=$(echo "${{ matrix.pair.brand }}" | sed 's/\\&/\&/g; s/\\"/"/g')
          PAGE_TYPE=$(echo "${{ matrix.pair.pageType }}" | sed 's/\\&/\&/g; s/\\"/"/g')
          
          cat > cypress.env.json << EOL
          {
            "Brandcode": "$BRAND",
            "PageType": "$PAGE_TYPE",
            "URL_1": "${{ matrix.pair.baseline }}",
            "URL_2": "${{ matrix.pair.modified }}"
          }
          EOL
          
          echo "Created cypress.env.json with content:"
          cat cypress.env.json
          
          # Run the appropriate test file based on viewport
          npx cypress run --browser chrome --headless --spec "cypress/e2e/regression-${{ matrix.viewport }}.cy.js"
          
          TEST_EXIT_CODE=$?
          echo "Test exit code: $TEST_EXIT_CODE"
          
          # Check if diff images were created (indicating visual differences)
          DIFF_COUNT=$(find cypress/screenshots -name "*diff*.png" | wc -l)
          if [ $DIFF_COUNT -gt 0 ]; then
            echo "Visual differences detected in $DIFF_COUNT screenshots"
            echo "has_diffs=true" >> $GITHUB_OUTPUT
          else
            echo "No visual differences detected"
            echo "has_diffs=false" >> $GITHUB_OUTPUT
          fi
          
          # Extract mismatch percentage from logs if available
          MISMATCH_PERCENTAGE=$(grep -o "Mismatch: [0-9.]*%" cypress/logs/regression-${{ matrix.viewport }}.log 2>/dev/null | tail -1 | cut -d' ' -f2 || echo "Unknown")
          
          # Create result summary
          mkdir -p test-results
          echo "{
            \"brand\": \"${{ matrix.pair.brand }}\",
            \"pageType\": \"${{ matrix.pair.pageType }}\",
            \"viewport\": \"${{ matrix.viewport }}\",
            \"baseline\": \"${{ matrix.pair.baseline }}\",
            \"modified\": \"${{ matrix.pair.modified }}\",
            \"status\": \"$([ $TEST_EXIT_CODE -eq 0 ] && echo 'success' || echo 'failure')\",
            \"has_diffs\": \"$([ $DIFF_COUNT -gt 0 ] && echo 'true' || echo 'false')\",
            \"mismatch\": \"$MISMATCH_PERCENTAGE\"
          }" > test-results/result-${{ matrix.pair.brand }}-${{ matrix.pair.pageType }}-${{ matrix.viewport }}.json
          
          # Log test completion
          echo "âœ… Test for ${{ matrix.viewport }} viewport completed, results saved to test-results/result-${{ matrix.pair.brand }}-${{ matrix.pair.pageType }}-${{ matrix.viewport }}.json"

      - name: Verify Test Completion
        run: |
          echo "Verifying test completion for ${{ matrix.viewport }} viewport..."
          if [ -f "test-results/result-${{ matrix.pair.brand }}-${{ matrix.pair.pageType }}-${{ matrix.viewport }}.json" ]; then
            echo "âœ… Test for ${{ matrix.viewport }} viewport completed successfully"
            cat "test-results/result-${{ matrix.pair.brand }}-${{ matrix.pair.pageType }}-${{ matrix.viewport }}.json"
          else
            echo "âŒ Test results not found for ${{ matrix.viewport }} viewport"
            exit 1
          fi

      - name: Upload Screenshots
        uses: actions/upload-artifact@v4
        with:
          name: visual-test-${{ matrix.pair.brand }}-${{ matrix.pair.pageType }}-${{ matrix.viewport }}
          path: |
            cypress/screenshots/**/*.png
            test-results/*.json
          retention-days: 14

  verify-viewport-coverage:
    needs: visual-test
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Download Test Results
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts

      - name: Verify All Viewport Tests
        run: |
          echo "Verifying tests for all viewports..."
          
          # Check each required viewport
          for viewport in mobile tablet desktop; do
            COUNT=$(find ./artifacts -name "result-*-${viewport}.json" | wc -l)
            if [ $COUNT -eq 0 ]; then
              echo "::warning::âš ï¸ No test results found for $viewport viewport!"
              MISSING_VIEWPORTS="${MISSING_VIEWPORTS} ${viewport}"
            else
              echo "âœ… Found $COUNT test result(s) for $viewport viewport"
            fi
          done
          
          # Exit with error if any viewport is missing
          if [ ! -z "$MISSING_VIEWPORTS" ]; then
            echo "::error::âŒ Missing test results for viewports:${MISSING_VIEWPORTS}"
            echo "missing_viewports=${MISSING_VIEWPORTS}" >> $GITHUB_OUTPUT
            exit 1
          else
            echo "âœ… All viewport tests (mobile, tablet, desktop) completed successfully!"
          fi

  report-results:
    needs: [visual-test, verify-viewport-coverage]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Download Test Results
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts

      - name: Generate Report
        id: report
        run: |
          echo "### ðŸ–¼ï¸ Visual Comparison Test Results" > report.md
          echo "" >> report.md
          
          # Check if we have any results
          if [ -z "$(find ./artifacts -name "result-*.json" 2>/dev/null)" ]; then
            echo "No test results found. Please ensure your PR description includes visual test configurations in the correct format:" >> report.md
            echo "" >> report.md
            echo "```" >> report.md
            echo "## Visual Test" >> report.md
            echo "- Brand: BrandName" >> report.md
            echo "- PageType: HomePage" >> report.md
            echo "- Baseline: https://baseline-url.com" >> report.md
            echo "- Modified: https://modified-url.com" >> report.md
            echo "```" >> report.md
            
            echo "overall_status=skipped" >> $GITHUB_OUTPUT
            cat report.md
            exit 0
          fi
          
          echo "| Brand | Page Type | Viewport | Baseline | Modified | Status | Differences |" >> report.md
          echo "|-------|-----------|----------|----------|----------|--------|------------|" >> report.md
          
          # Process all result files
          OVERALL_STATUS="success"
          MISSING_VIEWPORTS=""
          
          # Check for completeness of viewport tests
          DESKTOP_COUNT=$(find ./artifacts -name "result-*-desktop.json" | wc -l)
          TABLET_COUNT=$(find ./artifacts -name "result-*-tablet.json" | wc -l)
          MOBILE_COUNT=$(find ./artifacts -name "result-*-mobile.json" | wc -l)
          
          if [ $DESKTOP_COUNT -eq 0 ] || [ $TABLET_COUNT -eq 0 ] || [ $MOBILE_COUNT -eq 0 ]; then
            echo "âš ï¸ **Warning: Not all viewport tests completed!**" >> report.md
            echo "" >> report.md
            [ $DESKTOP_COUNT -eq 0 ] && echo "- âŒ Desktop tests missing" >> report.md
            [ $TABLET_COUNT -eq 0 ] && echo "- âŒ Tablet tests missing" >> report.md
            [ $MOBILE_COUNT -eq 0 ] && echo "- âŒ Mobile tests missing" >> report.md
            echo "" >> report.md
            OVERALL_STATUS="failure"
          else
            echo "âœ… **All viewport tests completed successfully!**" >> report.md
            echo "" >> report.md
          fi
          
          for resultFile in $(find ./artifacts -name "result-*.json"); do
            BRAND=$(jq -r '.brand' "$resultFile")
            PAGE_TYPE=$(jq -r '.pageType' "$resultFile")
            VIEWPORT=$(jq -r '.viewport' "$resultFile")
            BASELINE=$(jq -r '.baseline' "$resultFile")
            MODIFIED=$(jq -r '.modified' "$resultFile")
            STATUS=$(jq -r '.status' "$resultFile")
            HAS_DIFFS=$(jq -r '.has_diffs' "$resultFile")
            
            # Set emoji based on status
            if [ "$STATUS" == "success" ]; then
              if [ "$HAS_DIFFS" == "true" ]; then
                STATUS_EMOJI="âš ï¸"
                STATUS_TEXT="Differences"
                OVERALL_STATUS="failure"
              else
                STATUS_EMOJI="âœ…"
                STATUS_TEXT="Passed"
              fi
            else
              STATUS_EMOJI="âŒ"
              STATUS_TEXT="Failed"
              OVERALL_STATUS="failure"
            fi
            
            # Get artifact name for linking
            ARTIFACT_NAME="visual-test-${BRAND}-${PAGE_TYPE}-${VIEWPORT}"
            
            echo "| $BRAND | $PAGE_TYPE | $VIEWPORT | [Link]($BASELINE) | [Link]($MODIFIED) | $STATUS_EMOJI $STATUS_TEXT | [View Screenshots](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> report.md
          done
          
          echo "" >> report.md
          echo "---" >> report.md
          echo "ðŸ“Ž **[Download All Screenshots](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})**" >> report.md
          
          if [ "$OVERALL_STATUS" == "success" ]; then
            echo "overall_status=success" >> $GITHUB_OUTPUT
          else
            echo "overall_status=failure" >> $GITHUB_OUTPUT
          fi
          
          cat report.md

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: mshick/add-pr-comment@v2
        with:
          message-path: report.md
          repo-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set PR Status
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const overallStatus = '${{ steps.report.outputs.overall_status }}';
            
            await github.rest.checks.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: 'Visual Comparison Tests',
              head_sha: context.payload.pull_request.head.sha,
              status: 'completed',
              conclusion: overallStatus === 'skipped' ? 'neutral' : overallStatus,
              output: {
                title: overallStatus === 'success' ? 'Visual tests passed' : 
                       overallStatus === 'skipped' ? 'No visual tests run' : 'Visual differences detected',
                summary: 'See PR comment for details and screenshots'
              }
            }); 